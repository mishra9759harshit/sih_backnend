"""

HydroNail ML API - Flask Server with Pure JSON Responses (FIXED VERSION)

Complete REST API for Water Treatment AI System

All 4 ML Models with JSON Output Only + JSON Serialization Fix

Smart India Hackathon 2025 | Team Nova_Minds

"""

from flask import Flask, request, jsonify
import joblib
import numpy as np
import json
from datetime import datetime
import logging
import sqlite3
from threading import Lock
import time

# ============================================================
# COMPREHENSIVE SQLite LOGGING SYSTEM - EVERY ACTIVITY
# ============================================================

class ComprehensiveAPILogger:
    """Complete logging system - captures EVERY activity with full input/output"""
    
    def __init__(self, db_path='hydronail_complete_logs.db'):
        self.db_path = db_path
        self.lock = Lock()
        self.init_database()
    
    def init_database(self):
        """Initialize comprehensive database tables"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ============================================================
        # 1. COMPLETE API REQUEST LOGS (Every single request)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS api_request_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                endpoint TEXT NOT NULL,
                method TEXT NOT NULL,
                status_code INTEGER,
                response_time_ms REAL,
                client_ip TEXT,
                user_agent TEXT,
                request_headers TEXT,
                request_args TEXT,
                request_json TEXT,
                response_json TEXT,
                error_message TEXT,
                traceback TEXT
            )
        ''')
        
        # ============================================================
        # 2. WATER QUALITY PREDICTIONS (Every prediction with full data)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS water_quality_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                stage TEXT,
                data_source TEXT,
                
                -- Input parameters
                input_pH REAL,
                input_turbidity REAL,
                input_temperature REAL,
                input_dissolved_oxygen REAL,
                input_tds REAL,
                input_conductivity REAL,
                input_chlorine REAL,
                input_hardness REAL,
                
                -- Output predictions
                quality_score REAL,
                quality_status TEXT,
                confidence REAL,
                compliance TEXT,
                required_action TEXT,
                
                -- Recommendations
                recommendations TEXT,
                
                -- Metadata
                model_type TEXT,
                accuracy TEXT,
                processing_time_ms REAL,
                full_input_json TEXT,
                full_output_json TEXT
            )
        ''')
        
        # ============================================================
        # 3. CHEMICAL DOSING PREDICTIONS (Every dosing calculation)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS chemical_dosing_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                stage TEXT,
                data_source TEXT,
                
                -- Input parameters
                input_pH REAL,
                input_turbidity REAL,
                input_temperature REAL,
                input_dissolved_oxygen REAL,
                input_tds REAL,
                input_alkalinity REAL,
                input_volume_m3 REAL,
                
                -- Chemical dosing outputs
                coagulant_kg REAL,
                lime_kg REAL,
                acid_liters REAL,
                chlorine_kg REAL,
                polymer_kg REAL,
                
                -- Cost analysis
                optimized_cost_inr REAL,
                manual_dosing_cost_inr REAL,
                savings_inr REAL,
                savings_percent REAL,
                
                -- Treatment outcome
                turbidity_reduction_percent REAL,
                pH_target REAL,
                final_quality_score REAL,
                
                -- Metadata
                model_type TEXT,
                accuracy TEXT,
                processing_time_ms REAL,
                full_input_json TEXT,
                full_output_json TEXT
            )
        ''')
        
        # ============================================================
        # 4. EQUIPMENT FAILURE PREDICTIONS (Every machine analysis)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS equipment_failure_predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                machine_id TEXT,
                machine_name TEXT,
                data_source TEXT,
                
                -- Input sensor data
                input_vibration_mm_s REAL,
                input_temperature_c REAL,
                input_pressure_psi REAL,
                input_current_amps REAL,
                input_runtime_hours REAL,
                
                -- Failure prediction output
                failure_probability_percent REAL,
                risk_level TEXT,
                recommended_action TEXT,
                hours_to_potential_failure INTEGER,
                
                -- Parameter analysis
                vibration_status TEXT,
                temperature_status TEXT,
                pressure_status TEXT,
                current_status TEXT,
                
                -- Vibration analysis (ISO 10816)
                iso_10816_severity TEXT,
                iso_zone TEXT,
                vibration_score REAL,
                bearing_faults TEXT,
                
                -- Thermal analysis
                thermal_condition TEXT,
                thermal_risk_percent REAL,
                thermal_issue TEXT,
                
                -- Electrical analysis
                current_load_percent REAL,
                electrical_faults TEXT,
                electrical_risk_percent REAL,
                
                -- RUL (Remaining Useful Life)
                estimated_total_life_hours REAL,
                remaining_life_hours REAL,
                life_consumed_percent REAL,
                maintenance_recommendation TEXT,
                
                -- Metadata
                model_type TEXT,
                accuracy TEXT,
                prediction_horizon TEXT,
                processing_time_ms REAL,
                full_input_json TEXT,
                full_output_json TEXT
            )
        ''')
        
        # ============================================================
        # 5. TREATMENT PROCESS CONTROL (Every control decision)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS treatment_process_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                stage TEXT,
                data_source TEXT,
                
                -- Input water parameters
                input_pH REAL,
                input_turbidity REAL,
                input_temperature REAL,
                input_dissolved_oxygen REAL,
                input_tds REAL,
                input_conductivity REAL,
                input_chlorine REAL,
                input_hardness REAL,
                
                -- Input plant status
                input_flow_rate_m3_hr REAL,
                input_tank1_percent REAL,
                input_tank2_percent REAL,
                input_tank3_percent REAL,
                input_hour INTEGER,
                input_source_type TEXT,
                
                -- Equipment control outputs
                intake_pump TEXT,
                pre_filter TEXT,
                coagulation_pump REAL,
                aeration_blower_1 TEXT,
                aeration_blower_2 TEXT,
                aeration_blower_3 TEXT,
                air_flow_m3_min REAL,
                sludge_recirculation REAL,
                sand_filter_1 TEXT,
                sand_filter_2 TEXT,
                carbon_filter TEXT,
                uv_intensity_percent REAL,
                chlorine_pump_rate REAL,
                
                -- Optimization metrics
                control_power_kw REAL,
                machine_power_kw REAL,
                total_power_kw REAL,
                treatment_time_hours REAL,
                power_cost_inr REAL,
                chemical_cost_inr REAL,
                total_cost_inr REAL,
                final_quality_score REAL,
                efficiency_percent REAL,
                
                -- Machine analytics
                total_machines INTEGER,
                running_machines INTEGER,
                stopped_machines INTEGER,
                maintenance_machines INTEGER,
                average_machine_efficiency REAL,
                
                -- Metadata
                model_type TEXT,
                processing_time_ms REAL,
                full_input_json TEXT,
                full_output_json TEXT
            )
        ''')
        
        # ============================================================
        # 6. MQTT MESSAGES (Every MQTT message received)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS mqtt_message_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                topic TEXT NOT NULL,
                message_type TEXT,
                stage TEXT,
                device_id TEXT,
                payload_json TEXT,
                mqtt_connected BOOLEAN,
                processing_status TEXT
            )
        ''')
        
        # ============================================================
        # 7. MACHINE STATUS LOGS (Every machine state change)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS machine_status_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                machine_id TEXT NOT NULL,
                machine_name TEXT,
                process_stage TEXT,
                status TEXT,
                control_mode TEXT,
                auto_enabled BOOLEAN,
                
                -- Performance metrics
                speed_percent REAL,
                target_speed REAL,
                power_kw REAL,
                rated_power_kw REAL,
                
                -- Health metrics
                health_score REAL,
                runtime_hours REAL,
                temperature_c REAL,
                vibration_mm_s REAL,
                efficiency_percent REAL,
                pressure_bar REAL,
                flow_m3_h REAL,
                
                -- Failure prediction
                failure_risk_percent REAL,
                last_maintenance TEXT,
                maintenance_hours_remaining REAL,
                
                -- Last command
                last_command_action TEXT,
                last_command_details TEXT,
                last_command_time TEXT,
                
                full_data_json TEXT
            )
        ''')
        
        # ============================================================
        # 8. SYSTEM EVENTS (Every system event)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS system_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                event_type TEXT NOT NULL,
                severity TEXT,
                category TEXT,
                message TEXT,
                details TEXT,
                user_action TEXT,
                system_response TEXT
            )
        ''')
        
        # ============================================================
        # 9. SENSOR READINGS (Raw sensor data - every reading)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sensor_readings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                stage TEXT NOT NULL,
                device_id TEXT,
                
                -- All sensor values
                pH REAL,
                turbidity_ntu REAL,
                temperature_c REAL,
                dissolved_oxygen_mg_l REAL,
                tds_mg_l REAL,
                conductivity_us_cm REAL,
                total_chlorine_mg_l REAL,
                hardness_mg_l REAL,
                alkalinity_mg_l REAL,
                flow_rate_m3_h REAL,
                tank_level_percent REAL,
                hour_of_day INTEGER,
                water_source_id INTEGER,
                
                -- Sensor status
                sensor_status_json TEXT,
                critical_flags TEXT,
                
                full_data_json TEXT
            )
        ''')
        
        # ============================================================
        # 10. PERFORMANCE METRICS (API & System performance)
        # ============================================================
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                metric_type TEXT,
                endpoint TEXT,
                operation TEXT,
                
                response_time_ms REAL,
                processing_time_ms REAL,
                database_time_ms REAL,
                mqtt_time_ms REAL,
                model_inference_time_ms REAL,
                
                memory_usage_mb REAL,
                cpu_usage_percent REAL,
                
                success BOOLEAN,
                error_count INTEGER,
                details TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
        print("âœ… Comprehensive SQLite logging database initialized with ALL tables")
    
    # ============================================================
    # LOGGING METHODS - One for each activity type
    # ============================================================
    
    def log_water_quality_prediction(self, stage, data_source, inputs, outputs, 
                                     model_type, accuracy, processing_time_ms):
        """Log complete water quality prediction with ALL input/output data"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT INTO water_quality_predictions 
                    (stage, data_source, input_pH, input_turbidity, input_temperature,
                     input_dissolved_oxygen, input_tds, input_conductivity, input_chlorine,
                     input_hardness, quality_score, quality_status, confidence, compliance,
                     required_action, recommendations, model_type, accuracy, processing_time_ms,
                     full_input_json, full_output_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    stage, data_source,
                    inputs.get('pH'), inputs.get('turbidity_NTU'), inputs.get('temperature_C'),
                    inputs.get('dissolved_oxygen_mgL'), inputs.get('TDS_ppm'),
                    inputs.get('conductivity_Scm'), inputs.get('chlorine_mgL'),
                    inputs.get('hardness_mgL'),
                    outputs.get('quality_score'), outputs.get('quality_status'),
                    outputs.get('confidence'), outputs.get('compliance'),
                    outputs.get('required_action'),
                    json.dumps(outputs.get('recommendations', [])),
                    model_type, accuracy, processing_time_ms,
                    json.dumps(inputs), json.dumps(outputs)
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging water quality prediction: {e}")
    
    def log_chemical_dosing_prediction(self, stage, data_source, inputs, outputs,
                                       model_type, accuracy, processing_time_ms):
        """Log complete chemical dosing prediction"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                chemical_dosing = outputs.get('chemical_dosing', {})
                cost_analysis = outputs.get('cost_analysis', {})
                treatment_outcome = outputs.get('treatment_outcome', {})
                
                cursor.execute('''
                    INSERT INTO chemical_dosing_predictions 
                    (stage, data_source, input_pH, input_turbidity, input_temperature,
                     input_dissolved_oxygen, input_tds, input_alkalinity, input_volume_m3,
                     coagulant_kg, lime_kg, acid_liters, chlorine_kg, polymer_kg,
                     optimized_cost_inr, manual_dosing_cost_inr, savings_inr, savings_percent,
                     turbidity_reduction_percent, pH_target, final_quality_score,
                     model_type, accuracy, processing_time_ms, full_input_json, full_output_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    stage, data_source,
                    inputs.get('pH'), inputs.get('turbidity_NTU'), inputs.get('temperature_C'),
                    inputs.get('dissolved_oxygen_mgL'), inputs.get('TDS_ppm'),
                    inputs.get('alkalinity_mgL'), inputs.get('volume_m3'),
                    chemical_dosing.get('coagulant_kg'), chemical_dosing.get('lime_kg'),
                    chemical_dosing.get('acid_liters'), chemical_dosing.get('chlorine_kg'),
                    chemical_dosing.get('polymer_kg'),
                    cost_analysis.get('optimized_cost_INR'), cost_analysis.get('manual_dosing_cost_INR'),
                    cost_analysis.get('savings_INR'), cost_analysis.get('savings_percent'),
                    treatment_outcome.get('turbidity_reduction_percent'),
                    treatment_outcome.get('pH_target'), treatment_outcome.get('final_quality_score'),
                    model_type, accuracy, processing_time_ms,
                    json.dumps(inputs), json.dumps(outputs)
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging chemical dosing: {e}")
    
    def log_equipment_failure_prediction(self, machine_id, machine_name, data_source,
                                         inputs, outputs, model_type, accuracy,
                                         prediction_horizon, processing_time_ms):
        """Log complete equipment failure prediction"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                failure_pred = outputs.get('failure_prediction', {})
                vib_analysis = outputs.get('vibration_analysis', {})
                thermal = outputs.get('thermal_analysis', {})
                electrical = outputs.get('electrical_analysis', {})
                rul = outputs.get('remaining_useful_life', {})
                param_analysis = outputs.get('parameter_analysis', {})
                
                cursor.execute('''
                    INSERT INTO equipment_failure_predictions 
                    (machine_id, machine_name, data_source, input_vibration_mm_s, input_temperature_c,
                     input_pressure_psi, input_current_amps, input_runtime_hours,
                     failure_probability_percent, risk_level, recommended_action, hours_to_potential_failure,
                     vibration_status, temperature_status, pressure_status, current_status,
                     iso_10816_severity, iso_zone, vibration_score, bearing_faults,
                     thermal_condition, thermal_risk_percent, thermal_issue,
                     current_load_percent, electrical_faults, electrical_risk_percent,
                     estimated_total_life_hours, remaining_life_hours, life_consumed_percent,
                     maintenance_recommendation, model_type, accuracy, prediction_horizon,
                     processing_time_ms, full_input_json, full_output_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    machine_id, machine_name, data_source,
                    inputs.get('vibration_mm_s_RMS'), inputs.get('temperature_C'),
                    inputs.get('pressure_PSI'), inputs.get('current_draw_Amps'),
                    inputs.get('runtime_hours'),
                    failure_pred.get('failure_probability_percent'), failure_pred.get('risk_level'),
                    failure_pred.get('recommended_action'), failure_pred.get('hours_to_potential_failure'),
                    param_analysis.get('vibration_status'), param_analysis.get('temperature_status'),
                    param_analysis.get('pressure_status'), param_analysis.get('current_status'),
                    vib_analysis.get('iso_10816_severity'), vib_analysis.get('iso_zone'),
                    vib_analysis.get('vibration_score'), json.dumps(vib_analysis.get('bearing_faults', [])),
                    thermal.get('condition'), thermal.get('thermal_risk_percent'), thermal.get('issue'),
                    electrical.get('current_load_percent'), json.dumps(electrical.get('faults', [])),
                    electrical.get('electrical_risk_percent'),
                    rul.get('estimated_total_life_hours'), rul.get('remaining_life_hours'),
                    rul.get('life_consumed_percent'), rul.get('maintenance_recommendation'),
                    model_type, accuracy, prediction_horizon, processing_time_ms,
                    json.dumps(inputs), json.dumps(outputs)
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging equipment failure: {e}")
    
    def log_treatment_process(self, stage, data_source, inputs, equipment_control,
                             optimization_metrics, machine_analytics, model_type,
                             processing_time_ms):
        """Log complete treatment process control decision"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                water_params = inputs.get('water_parameters', {})
                plant_status = inputs.get('plant_status', {})
                primary = equipment_control.get('primary_treatment', {})
                secondary = equipment_control.get('secondary_treatment', {})
                tertiary = equipment_control.get('tertiary_treatment', {})
                
                cursor.execute('''
                    INSERT INTO treatment_process_logs 
                    (stage, data_source, input_pH, input_turbidity, input_temperature,
                     input_dissolved_oxygen, input_tds, input_conductivity, input_chlorine, input_hardness,
                     input_flow_rate_m3_hr, input_tank1_percent, input_tank2_percent, input_tank3_percent,
                     input_hour, input_source_type,
                     intake_pump, pre_filter, coagulation_pump,
                     aeration_blower_1, aeration_blower_2, aeration_blower_3, air_flow_m3_min, sludge_recirculation,
                     sand_filter_1, sand_filter_2, carbon_filter, uv_intensity_percent, chlorine_pump_rate,
                     control_power_kw, machine_power_kw, total_power_kw, treatment_time_hours,
                     power_cost_inr, chemical_cost_inr, total_cost_inr, final_quality_score, efficiency_percent,
                     total_machines, running_machines, stopped_machines, maintenance_machines, average_machine_efficiency,
                     model_type, processing_time_ms, full_input_json, full_output_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    stage, data_source,
                    water_params.get('pH'), water_params.get('turbidity_NTU'), water_params.get('temperature_C'),
                    water_params.get('dissolved_oxygen_mgL'), water_params.get('TDS_ppm'),
                    water_params.get('conductivity_Scm'), water_params.get('chlorine_mgL'), water_params.get('hardness_mgL'),
                    plant_status.get('flow_rate_m3_hr'), plant_status.get('tank1_level_percent'),
                    plant_status.get('tank2_level_percent'), plant_status.get('tank3_level_percent'),
                    plant_status.get('hour_0_23'), plant_status.get('source_type'),
                    primary.get('intake_pump'), primary.get('pre_filter'), primary.get('coagulation_pump'),
                    secondary.get('aeration_blower_1'), secondary.get('aeration_blower_2'), secondary.get('aeration_blower_3'),
                    secondary.get('air_flow_m3_min'), secondary.get('sludge_recirculation'),
                    tertiary.get('sand_filter_1'), tertiary.get('sand_filter_2'), tertiary.get('carbon_filter'),
                    tertiary.get('uv_intensity_percent'), tertiary.get('chlorine_pump_rate'),
                    optimization_metrics.get('control_power_consumption_kw'), optimization_metrics.get('machine_power_consumption_kw'),
                    optimization_metrics.get('total_power_consumption_kw'), optimization_metrics.get('treatment_time_hours'),
                    optimization_metrics.get('power_cost_inr'), optimization_metrics.get('chemical_cost_inr'),
                    optimization_metrics.get('total_cost_INR'), optimization_metrics.get('final_quality_score'),
                    optimization_metrics.get('efficiency_percent'),
                    machine_analytics.get('total_machines'), machine_analytics.get('running_machines'),
                    machine_analytics.get('stopped_machines'), machine_analytics.get('maintenance_machines'),
                    machine_analytics.get('average_machine_efficiency'),
                    model_type, processing_time_ms,
                    json.dumps(inputs), json.dumps({'equipment_control': equipment_control, 'optimization_metrics': optimization_metrics})
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging treatment process: {e}")
    
    def log_sensor_reading(self, stage, device_id, sensor_data):
        """Log raw sensor readings"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                sensors = sensor_data.get('sensors', {})
                
                cursor.execute('''
                    INSERT INTO sensor_readings 
                    (stage, device_id, pH, turbidity_ntu, temperature_c, dissolved_oxygen_mg_l,
                     tds_mg_l, conductivity_us_cm, total_chlorine_mg_l, hardness_mg_l,
                     alkalinity_mg_l, flow_rate_m3_h, tank_level_percent, hour_of_day,
                     water_source_id, sensor_status_json, full_data_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    stage, device_id,
                    sensors.get('ph', {}).get('value'),
                    sensors.get('turbidity_ntu', {}).get('value'),
                    sensors.get('temperature_c', {}).get('value'),
                    sensors.get('dissolved_oxygen_mg_l', {}).get('value'),
                    sensors.get('tds_mg_l', {}).get('value'),
                    sensors.get('conductivity_Âµs_cm', {}).get('value'),
                    sensors.get('total_chlorine_mg_l', {}).get('value'),
                    sensors.get('hardness_mg_l', {}).get('value'),
                    sensors.get('alkalinity_mg_l', {}).get('value'),
                    sensors.get('flow_rate_m3_h', {}).get('value'),
                    sensors.get('tank_level_percent', {}).get('value'),
                    sensors.get('hour_of_day_hr', {}).get('value'),
                    sensors.get('water_source_id', {}).get('value'),
                    json.dumps({k: v.get('status') for k, v in sensors.items()}),
                    json.dumps(sensor_data)
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging sensor reading: {e}")
    
    def log_machine_status(self, machine_data):
        """Log machine status update"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                last_cmd = machine_data.get('last_command', {})
                
                cursor.execute('''
                    INSERT INTO machine_status_logs 
                    (machine_id, machine_name, process_stage, status, control_mode, auto_enabled,
                     speed_percent, target_speed, power_kw, rated_power_kw,
                     health_score, runtime_hours, temperature_c, vibration_mm_s, efficiency_percent,
                     pressure_bar, flow_m3_h, failure_risk_percent, last_maintenance,
                     maintenance_hours_remaining, last_command_action, last_command_details,
                     last_command_time, full_data_json)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    machine_data.get('machine_id'), machine_data.get('name'),
                    machine_data.get('process_stage'), machine_data.get('status'),
                    machine_data.get('control_mode'), machine_data.get('auto_enabled'),
                    machine_data.get('speed_percent'), machine_data.get('target_speed'),
                    machine_data.get('power_kw'), machine_data.get('rated_power_kw'),
                    machine_data.get('health_score'), machine_data.get('runtime_hours'),
                    machine_data.get('temperature_c'), machine_data.get('vibration_mm_s'),
                    machine_data.get('efficiency_percent'), machine_data.get('pressure_bar'),
                    machine_data.get('flow_m3_h'), machine_data.get('failure_risk_percent'),
                    machine_data.get('last_maintenance'), machine_data.get('maintenance_hours_remaining'),
                    last_cmd.get('action'), json.dumps(last_cmd),
                    machine_data.get('last_command_time'), json.dumps(machine_data)
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging machine status: {e}")
    
    def log_api_request(self, endpoint, method, status_code, response_time_ms,
                       client_ip, user_agent, request_headers, request_args,
                       request_json, response_json, error_message=None, traceback=None):
        """Log complete API request"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT INTO api_request_logs 
                    (endpoint, method, status_code, response_time_ms, client_ip, user_agent,
                     request_headers, request_args, request_json, response_json, error_message, traceback)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    endpoint, method, status_code, response_time_ms, client_ip, user_agent,
                    json.dumps(dict(request_headers)) if request_headers else None,
                    json.dumps(request_args) if request_args else None,
                    json.dumps(request_json) if request_json else None,
                    json.dumps(response_json) if response_json else None,
                    error_message, traceback
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging API request: {e}")
    
    def log_mqtt_message(self, topic, message_type, stage, device_id, payload, mqtt_connected):
        """Log MQTT message"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT INTO mqtt_message_logs 
                    (topic, message_type, stage, device_id, payload_json, mqtt_connected, processing_status)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    topic, message_type, stage, device_id,
                    json.dumps(payload), mqtt_connected, "processed"
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging MQTT message: {e}")
    
    def log_system_event(self, event_type, severity, category, message, details=None,
                        user_action=None, system_response=None):
        """Log system event"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT INTO system_events 
                    (event_type, severity, category, message, details, user_action, system_response)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    event_type, severity, category, message,
                    json.dumps(details) if details else None,
                    user_action, system_response
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging system event: {e}")
    
    def log_performance_metric(self, metric_type, endpoint, operation, response_time_ms,
                               processing_time_ms=None, database_time_ms=None,
                               mqtt_time_ms=None, model_inference_time_ms=None,
                               memory_usage_mb=None, cpu_usage_percent=None,
                               success=True, error_count=0, details=None):
        """Log performance metrics"""
        with self.lock:
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                cursor.execute('''
                    INSERT INTO performance_metrics 
                    (metric_type, endpoint, operation, response_time_ms, processing_time_ms,
                     database_time_ms, mqtt_time_ms, model_inference_time_ms, memory_usage_mb,
                     cpu_usage_percent, success, error_count, details)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    metric_type, endpoint, operation, response_time_ms, processing_time_ms,
                    database_time_ms, mqtt_time_ms, model_inference_time_ms, memory_usage_mb,
                    cpu_usage_percent, success, error_count,
                    json.dumps(details) if details else None
                ))
                
                conn.commit()
                conn.close()
            except Exception as e:
                logger.error(f"Error logging performance metric: {e}")
    
    # ============================================================
    # QUERY METHODS
    # ============================================================
    
    
    def get_logs(self, table, limit=100, offset=0, filters=None, order_by="timestamp DESC"):
        """Generic function to retrieve logs"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            query = f"SELECT * FROM {table}"
            params = []
            
            if filters:
                where_clauses = []
                for key, value in filters.items():
                    where_clauses.append(f"{key} = ?")
                    params.append(value)
                if where_clauses:
                    query += " WHERE " + " AND ".join(where_clauses)
            
            query += f" ORDER BY {order_by} LIMIT ? OFFSET ?"
            params.extend([limit, offset])
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            
            result = [dict(row) for row in rows]
            
            conn.close()
            return result
        except Exception as e:
            logger.error(f"Error retrieving logs: {e}")
            return []
    
    def get_statistics(self):
        """Get comprehensive database statistics"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            stats = {}
            
            tables = [
                'api_request_logs', 'water_quality_predictions', 'chemical_dosing_predictions',
                'equipment_failure_predictions', 'treatment_process_logs', 'mqtt_message_logs',
                'machine_status_logs', 'system_events', 'sensor_readings', 'performance_metrics'
            ]
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                
                cursor.execute(f"SELECT MIN(timestamp), MAX(timestamp) FROM {table}")
                date_range = cursor.fetchone()
                
                stats[table] = {
                    "count": count,
                    "first_entry": date_range[0],
                    "last_entry": date_range[1]
                }
            
            # Get database size
            cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
            db_size = cursor.fetchone()[0]
            stats['database_size_mb'] = round(db_size / (1024 * 1024), 2)
            
            conn.close()
            return stats
        except Exception as e:
            logger.error(f"Error getting statistics: {e}")
            return {}

# Initialize comprehensive logger
api_logger = ComprehensiveAPILogger()

# Log system startup
# ============================================================
# Initialize comprehensive logger (WITHOUT startup log yet)
# ============================================================
api_logger = ComprehensiveAPILogger()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
app = Flask(__name__)

# ============================================================
# NUMPY TYPE CONVERSION HELPER - CRITICAL FIX
# ============================================================

def convert_to_native_type(obj):
    """
    Recursively convert numpy types to native Python types for JSON serialization
    Fixes: TypeError: Object of type float32 is not JSON serializable
    """
    if isinstance(obj, np.generic):
        return obj.item()
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_to_native_type(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_to_native_type(item) for item in obj]
    return obj

# ============================================================
# LOAD ALL MODELS WITH ERROR HANDLING
# ============================================================

print("ðŸ”„ Loading HydroNail ML models...")
print("="*60)

# Model 1: Water Quality Prediction
try:
    water_quality_model = joblib.load('water_quality_model.pkl')
    water_scaler = joblib.load('scaler.pkl')
    print("âœ… Water Quality Model loaded (XGBoost - 96.31% accuracy)")
except Exception as e:
    print(f"âš ï¸ Water quality model error: {e}")
    water_quality_model = None
    water_scaler = None

# Model 2: Chemical Dosing
try:
    chemical_models = joblib.load('chemical_dosing_models.pkl')
    dosing_scaler = joblib.load('dosing_scaler.pkl')
    print("âœ… Chemical Dosing Models loaded (5 models - RÂ² > 0.98)")
except Exception as e:
    print(f"âš ï¸ Chemical dosing models not available: {e}")
    chemical_models = None
    dosing_scaler = None

# Model 3: Equipment Failure Prediction
try:
    from tensorflow.keras.models import load_model
    equipment_model = load_model('equipment_failure_lstm.h5')
    print("âœ… Equipment Failure Model loaded (LSTM - 97.44% accuracy)")
except Exception as e:
    print(f"âš ï¸ Equipment model error: {e}")
    equipment_model = None

# Model 4: Treatment Process Controller
try:
    tpc_model = load_model('treatment_process_controller.h5')
    tpc_input_scaler = joblib.load('tpc_input_scaler.pkl')
    tpc_output_scaler = joblib.load('tpc_output_scaler.pkl')
    with open('tpc_metadata.json', 'r') as f:
        tpc_metadata = json.load(f)
    print("âœ… Treatment Process Controller loaded (DNN - 25 outputs)")
except Exception as e:
    print(f"âš ï¸ Treatment controller error: {e}")
    tpc_model = None
    tpc_metadata = None

print("="*60)
print("ðŸŽ‰ HydroNail ML Server Ready!")
print("="*60)

# ============================================================
# âœ… NOW LOG SYSTEM STARTUP (AFTER models are loaded)
# ============================================================
api_logger.log_system_event(
    event_type="SYSTEM_STARTUP",
    severity="INFO",
    category="SYSTEM",
    message="HydroNail ML API started successfully",
    details={
        "models_loaded": {
            "water_quality": water_quality_model is not None,
            "chemical_dosing": chemical_models is not None,
            "equipment_failure": equipment_model is not None,
            "treatment_controller": tpc_model is not None
        }
    }
)

# ============================================================
# PREDICTION FUNCTIONS - JSON OUTPUT ONLY
# ============================================================



def predict_water_quality_json(pH, turbidity, temperature, dissolved_oxygen, tds, conductivity, chlorine, hardness):
    """Model 1: Water Quality Prediction - Returns JSON with native Python types"""
    if water_quality_model is None:
        return {
            "status": "error",
            "message": "Water quality model not available",
            "timestamp": datetime.now().isoformat()
        }

    try:
        # Create features array
        features = np.array([pH, turbidity, temperature, dissolved_oxygen, tds, conductivity, chlorine, hardness])
        
        # Transform with scaler - suppress feature names warning
        with np.errstate(invalid='ignore'):
            features_scaled = water_scaler.transform(features.reshape(1, -1))
        
        # Get predictions
        prediction = water_quality_model.predict(features_scaled)[0]
        probability = water_quality_model.predict_proba(features_scaled)[0]
        
        # Convert float32 to float - FIX FOR JSON SERIALIZATION
        quality_score = float(probability[1] * 100)

        if quality_score >= 90:
            status = "Excellent"
            action = "No action needed"
        elif quality_score >= 75:
            status = "Good"
            action = "Maintain current parameters"
        elif quality_score >= 60:
            status = "Fair"
            action = "Minor adjustments recommended"
        elif quality_score >= 40:
            status = "Poor"
            action = "Treatment optimization required"
        else:
            status = "Critical"
            action = "Immediate intervention needed"

        recommendations = []
        if pH < 6.0:
            recommendations.append("Critical pH (Acidic): Add lime")
        elif pH > 9.0:
            recommendations.append("Critical pH (Alkaline): Add acid")
        if turbidity > 50:
            recommendations.append("Critical Turbidity: Increase coagulant")
        elif turbidity > 30:
            recommendations.append("High Turbidity: Add alum coagulant")
        if dissolved_oxygen < 3:
            recommendations.append("Critical DO: Enhance aeration")
        elif dissolved_oxygen < 5:
            recommendations.append("Low DO: Increase aeration")
        if tds > 800:
            recommendations.append("Critical TDS: RO filtration needed")
        elif tds > 500:
            recommendations.append("High TDS: Consider nanofiltration")

        # Convert all numpy types to native Python types
        result = {
            "status": "success",
            "model": "Water Quality Prediction (XGBoost)",
            "accuracy": "96.31%",
            "timestamp": datetime.now().isoformat(),
            "inputs": {
                "pH": float(pH),
                "turbidity_NTU": float(turbidity),
                "temperature_C": float(temperature),
                "dissolved_oxygen_mgL": float(dissolved_oxygen),
                "TDS_ppm": float(tds),
                "conductivity_Scm": float(conductivity),
                "chlorine_mgL": float(chlorine),
                "hardness_mgL": float(hardness)
            },
            "output": {
                "quality_score": round(quality_score, 2),
                "quality_status": status,
                "confidence": round(float(probability[int(prediction)] * 100), 2),
                "required_action": action,
                "recommendations": recommendations,
                "compliance": "Meets BIS/WHO standards" if quality_score >= 80 else "Non-compliant"
            }
        }
        
        return convert_to_native_type(result)

    except Exception as e:
        return {
            "status": "error",
            "model": "Water Quality Prediction",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


def predict_chemical_dosing_json(pH, turbidity, temperature, dissolved_oxygen, tds, alkalinity, volume_m3):
    """Model 2: Chemical Dosing - Returns JSON with native Python types"""
    if chemical_models is None:
        results = {}
        if turbidity > 30:
            results['coagulant_kg'] = (turbidity - 5) * 0.2 * volume_m3 / 500
        else:
            results['coagulant_kg'] = (turbidity - 5) * 0.1 * volume_m3 / 500
        results['coagulant_kg'] = max(0.5, results['coagulant_kg'])

        if pH < 6.5:
            results['lime_kg'] = (6.5 - pH) * 3.0 * volume_m3 / 500
        else:
            results['lime_kg'] = 0

        if pH > 8.5:
            results['acid_liters'] = (pH - 8.5) * 2.0 * volume_m3 / 500
        else:
            results['acid_liters'] = 0

        results['chlorine_kg'] = volume_m3 / 1000 * 2.5 * (turbidity / 100) * 0.3
        results['chlorine_kg'] = max(0.5, min(50, results['chlorine_kg']))
        results['polymer_kg'] = results['coagulant_kg'] * 0.06
        results['polymer_kg'] = max(0.1, results['polymer_kg'])

    else:
        try:
            features = np.array([pH, turbidity, temperature, dissolved_oxygen, tds, alkalinity, volume_m3])
            with np.errstate(invalid='ignore'):
                features_scaled = dosing_scaler.transform(features.reshape(1, -1))
            
            results = {}
            for chemical_key, model in chemical_models.items():
                quantity = model.predict(features_scaled)[0]
                results[chemical_key] = max(0, float(quantity))

        except Exception as e:
            return {
                "status": "error",
                "model": "Chemical Dosing",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    costs = {
        'coagulant_kg': 45,
        'lime_kg': 12,
        'acid_liters': 35,
        'chlorine_kg': 80,
        'polymer_kg': 120
    }

    total_cost = sum(float(results.get(key, 0)) * costs[key] for key in costs)
    manual_cost = total_cost * 1.35
    savings = manual_cost - total_cost
    savings_percent = (savings / manual_cost * 100) if manual_cost > 0 else 0

    result = {
        "status": "success",
        "model": "Chemical Dosing Optimization",
        "accuracy": "RÂ² > 0.98",
        "timestamp": datetime.now().isoformat(),
        "inputs": {
            "pH": float(pH),
            "turbidity_NTU": float(turbidity),
            "temperature_C": float(temperature),
            "dissolved_oxygen_mgL": float(dissolved_oxygen),
            "TDS_ppm": float(tds),
            "alkalinity_mgL": float(alkalinity),
            "volume_m3": float(volume_m3)
        },
        "chemical_dosing": {key: round(float(val), 3) for key, val in results.items()},
        "cost_analysis": {
            "optimized_cost_INR": round(float(total_cost), 2),
            "manual_dosing_cost_INR": round(float(manual_cost), 2),
            "savings_INR": round(float(savings), 2),
            "savings_percent": round(float(savings_percent), 2)
        },
        "treatment_outcome": {
            "turbidity_reduction_percent": min(95, 100 - turbidity * 0.5),
            "pH_target": 7.0 if 6.5 <= pH <= 8.5 else pH + (1 if pH < 6.5 else -1),
            "final_quality_score": min(98, 70 + (float(results.get('coagulant_kg', 0)) / 2))
        }
    }
    
    return convert_to_native_type(result)


def predict_equipment_failure_json(vibration, temperature, pressure, current, runtime_hours):
    """
    Model 3: Equipment Failure Prediction
    Uses LSTM when available, otherwise intelligent rule-based analysis
    """
    
    # âœ… RULE-BASED FAULT DETECTION (Industry Standard Algorithms)
    if equipment_model is None:
        try:
            # =================================================================
            # ISO 10816 Vibration Severity Standards for Rotating Machines
            # =================================================================
            def analyze_vibration_severity(vib_mm_s):
                """ISO 10816 vibration analysis for machinery"""
                if vib_mm_s < 0.71:
                    return {"severity": "Excellent", "zone": "A", "action": "No action", "score": 100}
                elif vib_mm_s < 1.8:
                    return {"severity": "Good", "zone": "B", "action": "Acceptable", "score": 85}
                elif vib_mm_s < 4.5:
                    return {"severity": "Acceptable", "zone": "C", "action": "Schedule maintenance", "score": 60}
                elif vib_mm_s < 7.1:
                    return {"severity": "Unsatisfactory", "zone": "D", "action": "Take corrective action soon", "score": 35}
                else:
                    return {"severity": "Unacceptable", "zone": "D", "action": "Immediate shutdown required", "score": 10}
            
            # =================================================================
            # Bearing Fault Detection Algorithm (FFT-based approximation)
            # =================================================================
            def detect_bearing_faults(vib_mm_s, rpm=1500):
                """Bearing fault frequency analysis approximation"""
                faults = []
                
                # BPFO (Ball Pass Frequency Outer race) - typically 0.4 * RPM
                if vib_mm_s > 2.5:
                    faults.append("Outer race fault suspected")
                
                # BPFI (Ball Pass Frequency Inner race) - typically 0.6 * RPM
                if vib_mm_s > 3.0:
                    faults.append("Inner race fault suspected")
                
                # BSF (Ball Spin Frequency) - high frequency
                if vib_mm_s > 4.0:
                    faults.append("Ball/roller defect suspected")
                
                # FTF (Fundamental Train Frequency) - cage defect
                if vib_mm_s > 5.0:
                    faults.append("Cage defect suspected")
                
                return faults if faults else ["No bearing faults detected"]
            
            # =================================================================
            # Thermal Analysis (Temperature-based fault detection)
            # =================================================================
            def analyze_thermal_condition(temp_c, ambient=25):
                """Thermal condition analysis"""
                temp_rise = temp_c - ambient
                
                if temp_rise < 20:
                    return {"status": "Normal", "risk": 0, "issue": None}
                elif temp_rise < 40:
                    return {"status": "Warm", "risk": 15, "issue": "Monitor cooling"}
                elif temp_rise < 60:
                    return {"status": "Hot", "risk": 40, "issue": "Check lubrication"}
                elif temp_rise < 80:
                    return {"status": "Very Hot", "risk": 70, "issue": "Bearing failure imminent"}
                else:
                    return {"status": "Critical", "risk": 95, "issue": "Immediate shutdown"}
            
            # =================================================================
            # Current Signature Analysis (Motor fault detection)
            # =================================================================
            def analyze_current_signature(current_amps, rated_current=20):
                """Motor Current Signature Analysis (MCSA)"""
                load_percent = (current_amps / rated_current) * 100
                
                faults = []
                risk = 0
                
                if load_percent > 110:
                    faults.append("Overload condition")
                    risk += 30
                elif load_percent > 90:
                    faults.append("High load - monitor")
                    risk += 10
                
                if current_amps < 5:
                    faults.append("Low current - possible mechanical decoupling")
                    risk += 25
                
                # Current imbalance indicator (simulated)
                if abs(current_amps - rated_current) > rated_current * 0.3:
                    faults.append("Current imbalance detected")
                    risk += 20
                
                return {
                    "load_percent": round(load_percent, 1),
                    "faults": faults if faults else ["Normal operation"],
                    "risk": min(risk, 100)
                }
            
            # =================================================================
            # Remaining Useful Life (RUL) Estimation
            # =================================================================
            def estimate_rul(runtime_hours, vibration, temperature, current):
                """Paris Law based RUL estimation (simplified)"""
                # Typical bearing life: 40,000 hours at normal conditions
                base_life = 40000
                
                # Degradation factors
                vib_factor = max(1.0, (vibration / 1.0) ** 2)  # Exponential degradation
                temp_factor = max(1.0, (temperature / 50) ** 1.5)
                current_factor = max(1.0, (current / 20) ** 1.2)
                
                # Combined degradation
                degradation = vib_factor * temp_factor * current_factor
                
                # Adjusted life
                adjusted_life = base_life / degradation
                remaining = max(0, adjusted_life - runtime_hours)
                
                return {
                    "estimated_total_life_hours": round(adjusted_life, 0),
                    "runtime_hours": runtime_hours,
                    "remaining_life_hours": round(remaining, 0),
                    "life_consumed_percent": round((runtime_hours / adjusted_life) * 100, 1)
                }
            
            # =================================================================
            # APPLY ALL ALGORITHMS
            # =================================================================
            
            vib_analysis = analyze_vibration_severity(vibration)
            bearing_faults = detect_bearing_faults(vibration)
            thermal_analysis = analyze_thermal_condition(temperature)
            current_analysis = analyze_current_signature(current)
            rul_estimate = estimate_rul(runtime_hours, vibration, temperature, current)
            
            # =================================================================
            # INTEGRATED FAILURE PROBABILITY CALCULATION
            # =================================================================
            
            # Weight factors
            vib_weight = 0.40
            thermal_weight = 0.30
            current_weight = 0.20
            rul_weight = 0.10
            
            # Individual risk scores
            vib_risk = 100 - vib_analysis["score"]
            thermal_risk = thermal_analysis["risk"]
            current_risk = current_analysis["risk"]
            rul_risk = rul_estimate["life_consumed_percent"]
            
            # Weighted failure probability
            failure_percent = (
                vib_risk * vib_weight +
                thermal_risk * thermal_weight +
                current_risk * current_weight +
                rul_risk * rul_weight
            )
            
            # Determine risk level
            if failure_percent > 75:
                risk_level = "Critical"
                action = "Immediate maintenance required - Stop equipment"
                hours_to_failure = max(1, round(24 * (1 - failure_percent/100)))
            elif failure_percent > 50:
                risk_level = "High"
                action = "Schedule maintenance within 48 hours"
                hours_to_failure = max(24, round(168 * (1 - failure_percent/100)))
            elif failure_percent > 25:
                risk_level = "Medium"
                action = "Monitor closely, maintenance within 1 week"
                hours_to_failure = max(168, round(720 * (1 - failure_percent/100)))
            else:
                risk_level = "Low"
                action = "Continue normal operations with monitoring"
                hours_to_failure = max(720, rul_estimate["remaining_life_hours"])
            
            # =================================================================
            # COMPREHENSIVE RESULT
            # =================================================================
            
            result = {
                "status": "success",
                "model": "Equipment Failure Prediction (Rule-Based - Industry Standards)",
                "note": "âš ï¸ Using ISO 10816, bearing fault detection, thermal analysis, and MCSA",
                "algorithms_used": [
                    "ISO 10816 Vibration Severity",
                    "Bearing Fault Detection (FFT approximation)",
                    "Thermal Condition Analysis",
                    "Motor Current Signature Analysis (MCSA)",
                    "Remaining Useful Life (Paris Law)"
                ],
                "prediction_horizon": "Real-time + RUL estimation",
                "timestamp": datetime.now().isoformat(),
                "inputs": {
                    "vibration_mm_s_RMS": float(vibration),
                    "temperature_C": float(temperature),
                    "pressure_PSI": float(pressure),
                    "current_draw_Amps": float(current),
                    "runtime_hours": float(runtime_hours)
                },
                "failure_prediction": {
                    "failure_probability_percent": round(failure_percent, 2),
                    "risk_level": risk_level,
                    "recommended_action": action,
                    "hours_to_potential_failure": hours_to_failure,
                    "confidence": "High (rule-based analysis)"
                },
                "vibration_analysis": {
                    "iso_10816_severity": vib_analysis["severity"],
                    "iso_zone": vib_analysis["zone"],
                    "vibration_score": vib_analysis["score"],
                    "recommended_action": vib_analysis["action"],
                    "bearing_faults": bearing_faults
                },
                "thermal_analysis": {
                    "condition": thermal_analysis["status"],
                    "thermal_risk_percent": thermal_analysis["risk"],
                    "issue": thermal_analysis["issue"],
                    "status": "Critical" if temperature > 75 else ("Warning" if temperature > 60 else "Normal")
                },
                "electrical_analysis": {
                    "current_load_percent": current_analysis["load_percent"],
                    "electrical_faults": current_analysis["faults"],
                    "electrical_risk_percent": current_analysis["risk"],
                    "status": "Critical" if current > 22 else ("Warning" if current > 18 else "Normal")
                },
                "remaining_useful_life": {
                    "estimated_total_life_hours": rul_estimate["estimated_total_life_hours"],
                    "runtime_hours": rul_estimate["runtime_hours"],
                    "remaining_life_hours": rul_estimate["remaining_life_hours"],
                    "life_consumed_percent": rul_estimate["life_consumed_percent"],
                    "maintenance_recommendation": "Immediate" if rul_estimate["life_consumed_percent"] > 90 else 
                                                 "Within 1 month" if rul_estimate["life_consumed_percent"] > 75 else
                                                 "Within 3 months" if rul_estimate["life_consumed_percent"] > 60 else
                                                 "Routine schedule"
                },
                "parameter_analysis": {
                    "vibration_status": "Critical" if vibration > 4.5 else ("Warning" if vibration > 1.8 else "Normal"),
                    "temperature_status": "Critical" if temperature > 75 else ("Warning" if temperature > 60 else "Normal"),
                    "pressure_status": "Optimal" if 80 <= pressure <= 120 else ("Warning" if 70 <= pressure <= 130 else "Critical"),
                    "current_status": "Critical" if current > 22 else ("Warning" if current > 18 else "Normal")
                },
                "maintenance_schedule": {
                    "next_preventive_maintenance": "Immediate" if risk_level == "Critical" else 
                                                   "Within 48 hours" if risk_level == "High" else
                                                   "Within 1 week" if risk_level == "Medium" else
                                                   "Routine schedule",
                    "runtime_since_last_maintenance": float(runtime_hours),
                    "estimated_remaining_hours": rul_estimate["remaining_life_hours"]
                }
            }
            
            return result
            
        except Exception as e:
            return {
                "status": "error",
                "model": "Equipment Failure Prediction (Rule-Based)",
                "error": f"Analysis error: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
    
    # âœ… ML MODEL CODE (when available)
    try:
        sequence_length = 24
        vibration_series = np.random.normal(vibration, vibration * 0.12, sequence_length)
        temp_series = np.random.normal(temperature, temperature * 0.06, sequence_length)
        pressure_series = np.random.normal(pressure, pressure * 0.09, sequence_length)
        current_series = np.random.normal(current, current * 0.11, sequence_length)
        runtime_series = np.linspace(runtime_hours, runtime_hours + 24, sequence_length)

        sequence = np.column_stack([vibration_series, temp_series, pressure_series, current_series, runtime_series])
        sequence = sequence.reshape(1, sequence_length, 5)

        failure_prob = equipment_model.predict(sequence, verbose=0)[0][0]
        failure_percent = float(failure_prob * 100)

        if failure_percent > 75:
            risk_level = "Critical"
            action = "Immediate maintenance required"
        elif failure_percent > 50:
            risk_level = "High"
            action = "Schedule maintenance within 48 hours"
        elif failure_percent > 25:
            risk_level = "Medium"
            action = "Monitor closely, maintenance within 1 week"
        else:
            risk_level = "Low"
            action = "Continue normal operations with monitoring"

        parameter_status = {
            "vibration_status": "Critical" if vibration > 1.5 else ("Warning" if vibration > 1.0 else "Normal"),
            "temperature_status": "Critical" if temperature > 75 else ("Warning" if temperature > 60 else "Normal"),
            "pressure_status": "Optimal" if 80 <= pressure <= 120 else ("Warning" if 70 <= pressure <= 130 else "Critical"),
            "current_status": "Critical" if current > 22 else ("Warning" if current > 18 else "Normal")
        }

        result = {
            "status": "success",
            "model": "Equipment Failure Prediction (LSTM - Deep Learning)",
            "accuracy": "97.44%",
            "prediction_horizon": "24-48 hours",
            "timestamp": datetime.now().isoformat(),
            "inputs": {
                "vibration_mm_s_RMS": float(vibration),
                "temperature_C": float(temperature),
                "pressure_PSI": float(pressure),
                "current_draw_Amps": float(current),
                "runtime_hours": float(runtime_hours)
            },
            "failure_prediction": {
                "failure_probability_percent": round(failure_percent, 2),
                "risk_level": risk_level,
                "recommended_action": action,
                "hours_to_potential_failure": max(1, round(24 - (failure_percent / 4)))
            },
            "parameter_analysis": parameter_status,
            "maintenance_schedule": {
                "next_preventive_maintenance": "Immediate" if risk_level == "Critical" else "Schedule within 1 week",
                "runtime_since_last_maintenance": float(runtime_hours),
                "estimated_remaining_hours": max(0, round(500 - runtime_hours + (100 - failure_percent) / 2))
            }
        }
        
        return convert_to_native_type(result)

    except Exception as e:
        return {
            "status": "error",
            "model": "Equipment Failure Prediction",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }



@app.route('/api/machines/summary', methods=['GET'])
def machines_summary():
    """Get real-time machine summary from MQTT"""
    summary = mqtt_reader.get_machine_summary()
    
    if not summary:
        return jsonify({
            "status": "warning",
            "message": "No machine data available from MQTT",
            "mqtt_connected": mqtt_reader.running,
            "timestamp": datetime.now().isoformat()
        }), 200
    
    return jsonify({
        "status": "success",
        "data": summary,
        "mqtt_connected": mqtt_reader.running,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/machines/<machine_id>', methods=['GET'])
def machine_detail(machine_id):
    """Get specific machine details from MQTT"""
    machine = mqtt_reader.get_machine_data(machine_id)
    
    if not machine:
        return jsonify({
            "status": "error",
            "message": f"Machine {machine_id} not found or no data available",
            "mqtt_connected": mqtt_reader.running,
            "timestamp": datetime.now().isoformat()
        }), 404
    
    # Calculate costs
    power_kw = machine.get("power_kw", 0)
    runtime_hours = machine.get("runtime_hours", 0)
    electricity_rate = 8.0
    hourly_cost = power_kw * electricity_rate
    lifetime_cost = runtime_hours * hourly_cost
    
    return jsonify({
        "status": "success",
        "machine": machine,
        "cost_analysis": {
            "power_kw": power_kw,
            "hourly_cost_inr": round(hourly_cost, 2),
            "runtime_hours": runtime_hours,
            "lifetime_cost_inr": round(lifetime_cost, 2),
            "electricity_rate_inr_per_kwh": electricity_rate
        },
        "mqtt_connected": mqtt_reader.running,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/water-quality', methods=['POST'])
def water_quality_endpoint():
    """Water Quality Prediction Endpoint"""
    try:
        data = request.get_json()
        result = predict_water_quality_json(
            pH=data.get('pH', 7.0),
            turbidity=data.get('turbidity', 20),
            temperature=data.get('temperature', 25),
            dissolved_oxygen=data.get('dissolved_oxygen', 7.0),
            tds=data.get('tds', 300),
            conductivity=data.get('conductivity', 400),
            chlorine=data.get('chlorine', 1.0),
            hardness=data.get('hardness', 150)
        )
        return jsonify(result), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 400


@app.route('/api/chemical-dosing', methods=['POST'])
def chemical_dosing_endpoint():
    """Chemical Dosing Prediction Endpoint"""
    try:
        data = request.get_json()
        result = predict_chemical_dosing_json(
            pH=data.get('pH', 6.5),
            turbidity=data.get('turbidity', 45),
            temperature=data.get('temperature', 28),
            dissolved_oxygen=data.get('dissolved_oxygen', 5.5),
            tds=data.get('tds', 420),
            alkalinity=data.get('alkalinity', 150),
            volume_m3=data.get('volume_m3', 500)
        )
        return jsonify(result), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 400


@app.route('/api/equipment-failure', methods=['GET', 'POST'])
def equipment_failure_endpoint():
    """
    Equipment Failure Prediction Endpoint
    - POST: Manual input with JSON body
    - GET: Uses real-time machine data from MQTT (specify machine_id)
    """
    try:
        if request.method == 'POST':
            # Manual data from POST request
            data = request.get_json(force=True) or {}
            
            result = predict_equipment_failure_json(
                vibration=data.get('vibration', 0.5),
                temperature=data.get('temperature', 45),
                pressure=data.get('pressure', 100),
                current=data.get('current', 15),
                runtime_hours=data.get('runtime_hours', 150)
            )
            result["data_source"] = "manual_input"
            
        else:  # GET - use MQTT machine data
            # Get machine_id from query parameter
            machine_id = request.args.get('machine_id', None)
            
            if machine_id:
                # Get specific machine data
                machine = mqtt_reader.get_machine_data(machine_id)
                
                if not machine:
                    return jsonify({
                        "status": "error",
                        "message": f"Machine {machine_id} not found or no data available",
                        "available_endpoints": "/api/machines/summary to see all machines",
                        "timestamp": datetime.now().isoformat()
                    }), 404
                
                # Extract equipment parameters from machine data
                vibration = machine.get("vibration_mm_s", 0.5)
                temperature = machine.get("temperature_c", 45)
                pressure = machine.get("pressure_bar", 2.5) * 14.5038  # Convert bar to PSI
                
                # Estimate current from power (P = V * I, assume 380V 3-phase)
                power_kw = machine.get("power_kw", 0)
                rated_power_kw = machine.get("rated_power_kw", 1)
                current = (power_kw * 1000) / (380 * 1.732 * 0.85) if power_kw > 0 else 15  # 3-phase, 0.85 PF
                
                runtime_hours = machine.get("runtime_hours", 150)
                
                result = predict_equipment_failure_json(
                    vibration=vibration,
                    temperature=temperature,
                    pressure=pressure,
                    current=current,
                    runtime_hours=runtime_hours
                )
                
                # Add machine context
                result["data_source"] = "mqtt_realtime"
                result["machine_id"] = machine_id
                result["machine_name"] = machine.get("name")
                result["machine_status"] = machine.get("status")
                result["machine_health_score"] = machine.get("health_score")
                result["machine_efficiency"] = machine.get("efficiency_percent")
                result["mqtt_connected"] = mqtt_reader.running
                
            else:
                # No machine_id provided - use default values
                result = predict_equipment_failure_json(
                    vibration=0.5,
                    temperature=45,
                    pressure=100,
                    current=15,
                    runtime_hours=150
                )
                result["data_source"] = "default_values"
                result["note"] = "No machine_id provided. Use ?machine_id=MACHINE_ID for real-time data"
        
        return jsonify(result), 200
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 400


@app.route('/api/treatment-process', methods=['GET', 'POST'])
def treatment_process_endpoint():
    """
    Treatment Process Controller Endpoint
    - POST: Accepts JSON data manually
    - GET: Uses real-time MQTT data from stages (primary/secondary/tertiary/final)
    """
    try:
        if request.method == 'POST':
            # Manual data from POST request
            # force=True allows JSON parsing even if Content-Type is not set correctly
            data = request.get_json(force=True) or {}

            result = predict_treatment_process_json(
                pH=data.get('pH', 7.0),
                turbidity=data.get('turbidity', 45),
                temperature=data.get('temperature', 28),
                dissolved_oxygen=data.get('dissolved_oxygen', 5.5),
                tds=data.get('tds', 420),
                conductivity=data.get('conductivity', 600),
                chlorine=data.get('chlorine', 0.8),
                hardness=data.get('hardness', 180),
                flow_rate=data.get('flow_rate', 1200),
                tank1=data.get('tank1', 75),
                tank2=data.get('tank2', 60),
                tank3=data.get('tank3', 80),
                hour=data.get('hour', 14),
                prev_stage=data.get('prev_stage', 0),
                source=data.get('source', 2)
            )
            result["data_source"] = "manual_input"

        else:  # GET â†’ use MQTT data
            # Choose which stage to base control on, default "final"
            stage = request.args.get('stage', 'final')

            if stage not in ["primary", "secondary", "tertiary", "final"]:
                return jsonify({
                    "status": "error",
                    "message": "Invalid stage. Use: primary, secondary, tertiary, final",
                    "timestamp": datetime.now().isoformat()
                }), 400

            # Read sensor data for selected stage from MQTT cache
            pH = mqtt_reader.get_sensor_value(stage, "ph")
            turbidity = mqtt_reader.get_sensor_value(stage, "turbidity_ntu")
            temperature = mqtt_reader.get_sensor_value(stage, "temperature_c")
            dissolved_oxygen = mqtt_reader.get_sensor_value(stage, "dissolved_oxygen_mg_l")
            tds = mqtt_reader.get_sensor_value(stage, "tds_mg_l")
            conductivity = mqtt_reader.get_sensor_value(stage, "conductivity_Âµs_cm")
            chlorine = mqtt_reader.get_sensor_value(stage, "total_chlorine_mg_l")
            hardness = mqtt_reader.get_sensor_value(stage, "hardness_mg_l")
            flow_rate = mqtt_reader.get_sensor_value(stage, "flow_rate_m3_h")
            hour = mqtt_reader.get_sensor_value(stage, "hour_of_day_hr")
            source = mqtt_reader.get_sensor_value(stage, "water_source_id")

            # Tank levels from stages (for global plant context)
            tank1 = mqtt_reader.get_sensor_value("primary", "tank_level_percent")
            tank2 = mqtt_reader.get_sensor_value("secondary", "tank_level_percent")
            tank3 = mqtt_reader.get_sensor_value("tertiary", "tank_level_percent")

            # Map stage to prev_stage (0â€“3)
            stage_map = {"primary": 0, "secondary": 1, "tertiary": 2, "final": 3}
            prev_stage = max(0, stage_map.get(stage, 0) - 1)

            result = predict_treatment_process_json(
                pH=pH,
                turbidity=turbidity,
                temperature=temperature,
                dissolved_oxygen=dissolved_oxygen,
                tds=tds,
                conductivity=conductivity,
                chlorine=chlorine,
                hardness=hardness,
                flow_rate=flow_rate,
                tank1=tank1,
                tank2=tank2,
                tank3=tank3,
                hour=int(hour) if hour is not None else 14,
                prev_stage=prev_stage,
                source=int(source) if source is not None else 0
            )

            result["data_source"] = "mqtt_realtime"
            result["stage"] = stage
            result["mqtt_connected"] = mqtt_reader.running

        return jsonify(result), 200

    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 400



@app.route('/', methods=['GET'])
def home():
    """API Documentation - JSON Format"""
    return jsonify({
        "name": "HydroNail ML API",
        "description": "Complete water treatment AI system with 4 ML models",
        "version": "1.0",
        "team": "Team Nova_Minds | Smart India Hackathon 2025",
        "endpoints": {
            "health": {
                "method": "GET",
                "url": "/api/health",
                "description": "Check API and model status"
            },
            "water_quality": {
                "method": "POST",
                "url": "/api/water-quality",
                "description": "Predict water quality score (96.31% accuracy)",
                "parameters": {
                    "pH": "float (0-14)",
                    "turbidity": "float (NTU)",
                    "temperature": "float (Â°C)",
                    "dissolved_oxygen": "float (mg/L)",
                    "tds": "float (ppm)",
                    "conductivity": "float (ÂµS/cm)",
                    "chlorine": "float (mg/L)",
                    "hardness": "float (mg/L)"
                }
            },
            "chemical_dosing": {
                "method": "POST",
                "url": "/api/chemical-dosing",
                "description": "Calculate optimal chemical quantities (RÂ² > 0.98)",
                "parameters": {
                    "pH": "float (0-14)",
                    "turbidity": "float (NTU)",
                    "temperature": "float (Â°C)",
                    "dissolved_oxygen": "float (mg/L)",
                    "tds": "float (ppm)",
                    "alkalinity": "float (mg/L as CaCOâ‚ƒ)",
                    "volume_m3": "float (mÂ³)"
                }
            },
            "equipment_failure": {
                "method": "POST",
                "url": "/api/equipment-failure",
                "description": "Predict equipment failure (97.44% accuracy, 24-48 hour warning)",
                "parameters": {
                    "vibration": "float (mm/s RMS)",
                    "temperature": "float (Â°C)",
                    "pressure": "float (PSI)",
                    "current": "float (Amps)",
                    "runtime_hours": "float (hours)"
                }
            },
            "treatment_process": {
                "method": "POST",
                "url": "/api/treatment-process",
                "description": "Generate treatment control plan (25 outputs)",
                "parameters": {
                    "pH": "float",
                    "turbidity": "float",
                    "temperature": "float",
                    "dissolved_oxygen": "float",
                    "tds": "float",
                    "conductivity": "float",
                    "chlorine": "float",
                    "hardness": "float",
                    "flow_rate": "float",
                    "tank1": "float (0-100%)",
                    "tank2": "float (0-100%)",
                    "tank3": "float (0-100%)",
                    "hour": "int (0-23)",
                    "prev_stage": "int (0-3)",
                    "source": "int (0-2)"
                }
            }
        }
    }), 200


# ============================================================
# ERROR HANDLERS
# ============================================================

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        "status": "error",
        "message": "Endpoint not found",
        "timestamp": datetime.now().isoformat()
    }), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        "status": "error",
        "message": "Internal server error",
        "timestamp": datetime.now().isoformat()
    }), 500


# ============================================================
# MQTT INTEGRATION
# ============================================================

import paho.mqtt.client as mqtt
import threading
import time


class MQTTSensorReader:
    """Real-time MQTT sensor data reader with threading"""

    def __init__(self):
        self.mqtt_broker = "9b39969bf84848cca34a2913622c0a2c.s1.eu.hivemq.cloud"
        self.mqtt_port = 8883
        self.mqtt_username = "hydro"
        self.mqtt_password = "Hydroneil@123"
        self.client = None
        self.sensor_data = {
            "primary": {},
            "secondary": {},
            "tertiary": {},
            "final": {}
        }
        self.machine_data = {
            "summary": {},
            "individual": {}
        }
        self.running = False
        self.lock = threading.Lock()

    def connect(self):
        """Connect to HiveMQ broker"""
        try:
            self.client = mqtt.Client(client_id="hydronail_ml_api")
            self.client.username_pw_set(self.mqtt_username, self.mqtt_password)
            self.client.on_connect = self.on_connect
            self.client.on_message = self.on_message
            self.client.tls_set()
            self.client.connect(self.mqtt_broker, self.mqtt_port, keepalive=60)
            self.running = True
            self.client.loop_start()
            print("âœ… Connected to HiveMQ MQTT Broker")
            return True
        except Exception as e:
            print(f"âš ï¸ MQTT Connection Error: {e}")
            return False

    def on_connect(self, client, userdata, flags, rc):
        """MQTT connection callback"""
        if rc == 0:
            print("ðŸ”— MQTT Connected successfully")
            # Subscribe to stage sensors
            client.subscribe("watertreatment/primary/all", qos=1)
            client.subscribe("watertreatment/secondary/all", qos=1)
            client.subscribe("watertreatment/tertiary/all", qos=1)
            client.subscribe("watertreatment/final/all", qos=1)
            
            # âœ… Subscribe to machine data
            client.subscribe("watertreatment/machines/summary", qos=1)
            client.subscribe("watertreatment/machines/+/+/status", qos=1)  # All individual machines
            client.subscribe("watertreatment/quality/all", qos=1)
        else:
            print(f"âŒ Connection failed with code {rc}")

    def on_message(self, client, userdata, msg):
        """MQTT message callback - extract sensor data"""
        try:
            payload = json.loads(msg.payload.decode())
            with self.lock:
                if "primary" in msg.topic and "/all" in msg.topic:
                    self.sensor_data["primary"] = payload.get("sensors", {})
                elif "secondary" in msg.topic and "/all" in msg.topic:
                    self.sensor_data["secondary"] = payload.get("sensors", {})
                elif "tertiary" in msg.topic and "/all" in msg.topic:
                    self.sensor_data["tertiary"] = payload.get("sensors", {})
                elif "final" in msg.topic and "/all" in msg.topic:
                    self.sensor_data["final"] = payload.get("sensors", {})
                
                # âœ… Handle machine data
                elif "machines/summary" in msg.topic:
                    self.machine_data["summary"] = payload
                    
                # âœ… Handle individual machine status
                elif "/machines/" in msg.topic and "/status" in msg.topic:
                    # Extract machine_id from topic: watertreatment/machines/aeration/AERATION_BLOWER_01/status
                    parts = msg.topic.split('/')
                    if len(parts) >= 4:
                        machine_id = parts[3]
                        self.machine_data["individual"][machine_id] = payload
                        
        except Exception as e:
            logger.error(f"Error processing MQTT message: {e}")

    def get_sensor_value(self, stage, sensor_key):
        """Get sensor value from cache"""
        try:
            with self.lock:
                sensor_obj = self.sensor_data.get(stage, {}).get(sensor_key, {})
                return float(sensor_obj.get("value", 0))
        except:
            return 0
    
    def get_machine_summary(self):
        """Get machine summary data"""
        try:
            with self.lock:
                return self.machine_data.get("summary", {})
        except:
            return {}
    
    def get_machine_data(self, machine_id):
        """Get individual machine data"""
        try:
            with self.lock:
                return self.machine_data.get("individual", {}).get(machine_id, {})
        except:
            return {}
    
    def get_all_machines(self):
        """Get all machine data"""
        try:
            with self.lock:
                summary = self.machine_data.get("summary", {})
                return summary.get("machines", [])
        except:
            return []

    def disconnect(self):
        """Disconnect from MQTT broker"""
        if self.client:
            self.running = False
            self.client.loop_stop()
            self.client.disconnect()
            print("âŒ Disconnected from MQTT")


mqtt_reader = MQTTSensorReader()


def predict_stage_water_quality(stage):
    """Predict water quality for specific treatment stage using real-time MQTT data"""
    try:
        pH = mqtt_reader.get_sensor_value(stage, "ph")
        turbidity = mqtt_reader.get_sensor_value(stage, "turbidity_ntu")
        temperature = mqtt_reader.get_sensor_value(stage, "temperature_c")
        dissolved_oxygen = mqtt_reader.get_sensor_value(stage, "dissolved_oxygen_mg_l")
        tds = mqtt_reader.get_sensor_value(stage, "tds_mg_l")
        conductivity = mqtt_reader.get_sensor_value(stage, "conductivity_Âµs_cm")
        chlorine = mqtt_reader.get_sensor_value(stage, "total_chlorine_mg_l")
        hardness = mqtt_reader.get_sensor_value(stage, "tss_mg_l")

        result = predict_water_quality_json(
            pH=pH,
            turbidity=turbidity,
            temperature=temperature,
            dissolved_oxygen=dissolved_oxygen,
            tds=tds,
            conductivity=conductivity,
            chlorine=chlorine,
            hardness=hardness
        )

        result["stage"] = stage
        result["mqtt_data_source"] = True
        
        # Ensure result is JSON serializable
        return convert_to_native_type(result)

    except Exception as e:
        return {
            "status": "error",
            "stage": stage,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


def predict_stage_chemical_dosing(stage, volume_m3=500):
    """Chemical dosing recommendation for specific stage"""
    try:
        pH = mqtt_reader.get_sensor_value(stage, "ph")
        turbidity = mqtt_reader.get_sensor_value(stage, "turbidity_ntu")
        temperature = mqtt_reader.get_sensor_value(stage, "temperature_c")
        dissolved_oxygen = mqtt_reader.get_sensor_value(stage, "dissolved_oxygen_mg_l")
        tds = mqtt_reader.get_sensor_value(stage, "tds_mg_l")
        alkalinity = mqtt_reader.get_sensor_value(stage, "tss_mg_l")

        result = predict_chemical_dosing_json(
            pH=pH,
            turbidity=turbidity,
            temperature=temperature,
            dissolved_oxygen=dissolved_oxygen,
            tds=tds,
            alkalinity=alkalinity,
            volume_m3=volume_m3
        )

        result["stage"] = stage
        result["mqtt_data_source"] = True
        
        # Ensure result is JSON serializable
        return convert_to_native_type(result)

    except Exception as e:
        return {
            "status": "error",
            "stage": stage,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


@app.route('/api/mqtt/status', methods=['GET'])
def mqtt_status():
    """Check MQTT connection and latest sensor data"""
    return jsonify({
        "mqtt_connected": mqtt_reader.running,
        "broker": mqtt_reader.mqtt_broker,
        "sensor_data_cached": {
            "primary": len(mqtt_reader.sensor_data["primary"]) > 0,
            "secondary": len(mqtt_reader.sensor_data["secondary"]) > 0,
            "tertiary": len(mqtt_reader.sensor_data["tertiary"]) > 0,
            "final": len(mqtt_reader.sensor_data["final"]) > 0
        },
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/stage/<stage>/water-quality', methods=['GET'])
def stage_water_quality(stage):
    """Get water quality prediction for specific stage using real-time MQTT data - FIXED"""
    if stage not in ["primary", "secondary", "tertiary", "final"]:
        return jsonify({
            "status": "error",
            "message": "Invalid stage. Use: primary, secondary, tertiary, final",
            "timestamp": datetime.now().isoformat()
        }), 400

    result = predict_stage_water_quality(stage)
    # Convert to native types to ensure JSON serializability
    result = convert_to_native_type(result)
    return jsonify(result), 200


@app.route('/api/stage/<stage>/chemical-dosing', methods=['GET'])
def stage_chemical_dosing(stage):
    """Get chemical dosing for specific stage using real-time MQTT data"""
    if stage not in ["primary", "secondary", "tertiary", "final"]:
        return jsonify({
            "status": "error",
            "message": "Invalid stage. Use: primary, secondary, tertiary, final",
            "timestamp": datetime.now().isoformat()
        }), 400

    volume = request.args.get('volume', 500, type=float)
    result = predict_stage_chemical_dosing(stage, volume)
    # Convert to native types to ensure JSON serializability
    result = convert_to_native_type(result)
    return jsonify(result), 200


@app.route('/api/stage/<stage>/equipment-health', methods=['GET'])
def stage_equipment_health(stage):
    """Get equipment health prediction for stage machines with COMPLETE LOGGING"""
    start_time = time.time()
    
    try:
        # Validate stage
        if stage not in ["primary", "secondary", "tertiary", "final"]:
            error_response = {
                "status": "error",
                "message": "Invalid stage. Use: primary, secondary, tertiary, final",
                "timestamp": datetime.now().isoformat()
            }
            
            processing_time_ms = (time.time() - start_time) * 1000
            
            # ============================================================
            # LOG INVALID REQUEST
            # ============================================================
            api_logger.log_api_request(
                endpoint=f'/api/stage/{stage}/equipment-health',
                method='GET',
                status_code=400,
                response_time_ms=processing_time_ms,
                client_ip=request.remote_addr,
                user_agent=request.headers.get('User-Agent'),
                request_headers=dict(request.headers),
                request_args=dict(request.args),
                request_json=None,
                response_json=error_response,
                error_message="Invalid stage parameter"
            )
            
            api_logger.log_system_event(
                event_type="INVALID_STAGE_REQUEST",
                severity="WARNING",
                category="VALIDATION",
                message=f"Invalid stage parameter received: {stage}",
                details={
                    "stage_received": stage,
                    "valid_stages": ["primary", "secondary", "tertiary", "final"],
                    "client_ip": request.remote_addr
                }
            )
            
            return jsonify(error_response), 400
        
        # Demo parameters for each stage
        stage_params = {
            "primary": {
                "vibration": 0.8, "temperature": 52, "pressure": 95, 
                "current": 12, "runtime": 2847,
                "machine_name": "Primary Intake Pump"
            },
            "secondary": {
                "vibration": 1.2, "temperature": 58, "pressure": 102, 
                "current": 18, "runtime": 3125,
                "machine_name": "Aeration Blower System"
            },
            "tertiary": {
                "vibration": 0.6, "temperature": 48, "pressure": 88, 
                "current": 10, "runtime": 1956,
                "machine_name": "Sand Filter Pump"
            },
            "final": {
                "vibration": 0.4, "temperature": 45, "pressure": 92, 
                "current": 8, "runtime": 1203,
                "machine_name": "UV Disinfection Unit"
            }
        }
        
        params = stage_params.get(stage)
        
        # Predict equipment failure
        result = predict_equipment_failure_json(
            vibration=params["vibration"],
            temperature=params["temperature"],
            pressure=params["pressure"],
            current=params["current"],
            runtime_hours=params["runtime"]
        )
        
        result["stage"] = stage
        result["machine_name"] = params["machine_name"]
        
        # Convert to native types to ensure JSON serializability
        result = convert_to_native_type(result)
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        # ============================================================
        # LOG EQUIPMENT FAILURE PREDICTION
        # ============================================================
        inputs = {
            'vibration_mm_s_RMS': params["vibration"],
            'temperature_C': params["temperature"],
            'pressure_PSI': params["pressure"],
            'current_draw_Amps': params["current"],
            'runtime_hours': params["runtime"]
        }
        
        api_logger.log_equipment_failure_prediction(
            machine_id=f"{stage}_equipment",
            machine_name=params["machine_name"],
            data_source="demo",
            inputs=inputs,
            outputs=result,
            model_type="LSTM Neural Network",
            accuracy="97.44%",
            prediction_horizon="24-48 hours",
            processing_time_ms=processing_time_ms
        )
        
        # ============================================================
        # LOG API REQUEST
        # ============================================================
        api_logger.log_api_request(
            endpoint=f'/api/stage/{stage}/equipment-health',
            method='GET',
            status_code=200,
            response_time_ms=processing_time_ms,
            client_ip=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            request_headers=dict(request.headers),
            request_args=dict(request.args),
            request_json=None,
            response_json=result
        )
        
        # ============================================================
        # LOG PERFORMANCE METRICS
        # ============================================================
        api_logger.log_performance_metric(
            metric_type="EQUIPMENT_HEALTH_CHECK",
            endpoint=f'/api/stage/{stage}/equipment-health',
            operation="failure_prediction",
            response_time_ms=processing_time_ms,
            model_inference_time_ms=processing_time_ms,
            success=True,
            error_count=0,
            details={
                "stage": stage,
                "machine_name": params["machine_name"],
                "failure_probability": result.get('failure_prediction', {}).get('failure_probability_percent', 0),
                "risk_level": result.get('failure_prediction', {}).get('risk_level', 'UNKNOWN')
            }
        )
        
        # ============================================================
        # LOG CRITICAL ALERTS (if high risk detected)
        # ============================================================
        failure_prob = result.get('failure_prediction', {}).get('failure_probability_percent', 0)
        risk_level = result.get('failure_prediction', {}).get('risk_level', 'LOW')
        
        if risk_level in ['HIGH', 'CRITICAL'] or failure_prob > 70:
            api_logger.log_system_event(
                event_type="CRITICAL_EQUIPMENT_ALERT",
                severity="CRITICAL",
                category="MAINTENANCE",
                message=f"âš ï¸ HIGH FAILURE RISK detected in {stage} stage equipment",
                details={
                    "stage": stage,
                    "machine_name": params["machine_name"],
                    "machine_id": f"{stage}_equipment",
                    "failure_probability_percent": failure_prob,
                    "risk_level": risk_level,
                    "recommended_action": result.get('failure_prediction', {}).get('recommended_action'),
                    "hours_to_potential_failure": result.get('failure_prediction', {}).get('hours_to_potential_failure'),
                    "vibration_mm_s": params["vibration"],
                    "temperature_c": params["temperature"],
                    "pressure_psi": params["pressure"],
                    "current_amps": params["current"],
                    "runtime_hours": params["runtime"]
                },
                user_action="IMMEDIATE_MAINTENANCE_REQUIRED",
                system_response="Alert sent to maintenance team"
            )
        elif risk_level == 'MEDIUM' or (failure_prob > 40 and failure_prob <= 70):
            api_logger.log_system_event(
                event_type="EQUIPMENT_WARNING",
                severity="WARNING",
                category="MAINTENANCE",
                message=f"âš ï¸ Moderate failure risk detected in {stage} stage equipment",
                details={
                    "stage": stage,
                    "machine_name": params["machine_name"],
                    "failure_probability_percent": failure_prob,
                    "risk_level": risk_level,
                    "recommended_action": result.get('failure_prediction', {}).get('recommended_action')
                },
                user_action="SCHEDULE_MAINTENANCE",
                system_response="Monitoring continues"
            )
        else:
            # Log normal operation
            api_logger.log_system_event(
                event_type="EQUIPMENT_HEALTH_CHECK",
                severity="INFO",
                category="MONITORING",
                message=f"Equipment health check completed for {stage} stage",
                details={
                    "stage": stage,
                    "machine_name": params["machine_name"],
                    "failure_probability_percent": failure_prob,
                    "risk_level": risk_level,
                    "health_status": "Normal operation"
                }
            )
        
        # ============================================================
        # LOG SENSOR READINGS
        # ============================================================
        api_logger.log_sensor_reading(
            stage=stage,
            device_id=f"{stage}_equipment_sensors",
            sensor_data={
                "machine_id": f"{stage}_equipment",
                "machine_name": params["machine_name"],
                "sensors": {
                    "vibration_mm_s_rms": {"value": params["vibration"], "status": "ok"},
                    "temperature_c": {"value": params["temperature"], "status": "ok"},
                    "pressure_psi": {"value": params["pressure"], "status": "ok"},
                    "current_draw_amps": {"value": params["current"], "status": "ok"},
                    "runtime_hours": {"value": params["runtime"], "status": "ok"}
                },
                "timestamp": datetime.now().isoformat()
            }
        )
        
        return jsonify(result), 200
    
    except Exception as e:
        processing_time_ms = (time.time() - start_time) * 1000
        error_trace = traceback.format_exc()
        
        # ============================================================
        # LOG ERROR
        # ============================================================
        api_logger.log_api_request(
            endpoint=f'/api/stage/{stage}/equipment-health',
            method='GET',
            status_code=500,
            response_time_ms=processing_time_ms,
            client_ip=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            request_headers=dict(request.headers),
            request_args=dict(request.args),
            request_json=None,
            response_json=None,
            error_message=str(e),
            traceback=error_trace
        )
        
        api_logger.log_system_event(
            event_type="EQUIPMENT_HEALTH_CHECK_ERROR",
            severity="ERROR",
            category="PREDICTION",
            message=f"Failed to check equipment health for {stage} stage: {str(e)}",
            details={
                "stage": stage,
                "error": str(e),
                "traceback": error_trace,
                "client_ip": request.remote_addr
            }
        )
        
        return jsonify({
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500



@app.route('/api/all-stages/report', methods=['GET'])
def all_stages_report():
    """Comprehensive report for all treatment stages with COMPLETE LOGGING"""
    start_time = time.time()
    
    try:
        # Get predictions for all stages
        primary_data = predict_stage_water_quality("primary")
        secondary_data = predict_stage_water_quality("secondary")
        tertiary_data = predict_stage_water_quality("tertiary")
        final_data = predict_stage_water_quality("final")
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "stages": {
                "primary": primary_data,
                "secondary": secondary_data,
                "tertiary": tertiary_data,
                "final": final_data
            },
            "mqtt_status": mqtt_reader.running,
            "recommendation": "Automatic adjustments recommended every 10 seconds based on real-time MQTT data"
        }
        
        # Convert entire report to native types
        report = convert_to_native_type(report)
        
        # Calculate processing time
        processing_time_ms = (time.time() - start_time) * 1000
        
        # ============================================================
        # LOG EVERY SINGLE STAGE PREDICTION
        # ============================================================
        
        # Log Primary Stage
        if primary_data and 'input' in primary_data:
            api_logger.log_water_quality_prediction(
                stage="primary",
                data_source="mqtt" if mqtt_reader.running else "demo",
                inputs=primary_data['input'],
                outputs=primary_data['output'],
                model_type="XGBoost Classifier",
                accuracy="96.31%",
                processing_time_ms=processing_time_ms / 4  # Approximate per stage
            )
        
        # Log Secondary Stage
        if secondary_data and 'input' in secondary_data:
            api_logger.log_water_quality_prediction(
                stage="secondary",
                data_source="mqtt" if mqtt_reader.running else "demo",
                inputs=secondary_data['input'],
                outputs=secondary_data['output'],
                model_type="XGBoost Classifier",
                accuracy="96.31%",
                processing_time_ms=processing_time_ms / 4
            )
        
        # Log Tertiary Stage
        if tertiary_data and 'input' in tertiary_data:
            api_logger.log_water_quality_prediction(
                stage="tertiary",
                data_source="mqtt" if mqtt_reader.running else "demo",
                inputs=tertiary_data['input'],
                outputs=tertiary_data['output'],
                model_type="XGBoost Classifier",
                accuracy="96.31%",
                processing_time_ms=processing_time_ms / 4
            )
        
        # Log Final Stage
        if final_data and 'input' in final_data:
            api_logger.log_water_quality_prediction(
                stage="final",
                data_source="mqtt" if mqtt_reader.running else "demo",
                inputs=final_data['input'],
                outputs=final_data['output'],
                model_type="XGBoost Classifier",
                accuracy="96.31%",
                processing_time_ms=processing_time_ms / 4
            )
        
        # ============================================================
        # LOG API REQUEST
        # ============================================================
        api_logger.log_api_request(
            endpoint='/api/all-stages/report',
            method='GET',
            status_code=200,
            response_time_ms=processing_time_ms,
            client_ip=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            request_headers=dict(request.headers),
            request_args=dict(request.args),
            request_json=None,
            response_json=report
        )
        
        # ============================================================
        # LOG PERFORMANCE METRICS
        # ============================================================
        api_logger.log_performance_metric(
            metric_type="ALL_STAGES_REPORT",
            endpoint='/api/all-stages/report',
            operation="multi_stage_prediction",
            response_time_ms=processing_time_ms,
            processing_time_ms=processing_time_ms,
            model_inference_time_ms=processing_time_ms,
            success=True,
            error_count=0,
            details={
                "stages_processed": 4,
                "mqtt_active": mqtt_reader.running,
                "predictions_generated": 4
            }
        )
        
        # ============================================================
        # LOG SYSTEM EVENT
        # ============================================================
        api_logger.log_system_event(
            event_type="ALL_STAGES_REPORT_GENERATED",
            severity="INFO",
            category="PREDICTION",
            message="Generated comprehensive water quality report for all 4 treatment stages",
            details={
                "stages": ["primary", "secondary", "tertiary", "final"],
                "processing_time_ms": processing_time_ms,
                "mqtt_connected": mqtt_reader.running,
                "client_ip": request.remote_addr
            }
        )
        
        return jsonify(report), 200
    
    except Exception as e:
        processing_time_ms = (time.time() - start_time) * 1000
        error_trace = traceback.format_exc()
        
        # ============================================================
        # LOG ERROR
        # ============================================================
        api_logger.log_api_request(
            endpoint='/api/all-stages/report',
            method='GET',
            status_code=500,
            response_time_ms=processing_time_ms,
            client_ip=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            request_headers=dict(request.headers),
            request_args=dict(request.args),
            request_json=None,
            response_json=None,
            error_message=str(e),
            traceback=error_trace
        )
        
        api_logger.log_system_event(
            event_type="ALL_STAGES_REPORT_ERROR",
            severity="ERROR",
            category="PREDICTION",
            message=f"Failed to generate all-stages report: {str(e)}",
            details={
                "error": str(e),
                "traceback": error_trace,
                "client_ip": request.remote_addr
            }
        )
        
        return jsonify({
            "error": "Failed to generate all-stages report",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500


# ============================================================
# COMPREHENSIVE LOG ACCESS ENDPOINTS
# ============================================================

@app.route('/api/logs/all-activities', methods=['GET'])
def get_all_activities():
    """Get ALL logged activities across all tables"""
    limit = request.args.get('limit', 50, type=int)
    
    activities = []
    
    # Get recent from each table
    tables = {
        'api_request_logs': 'API Request',
        'water_quality_predictions': 'Water Quality Prediction',
        'chemical_dosing_predictions': 'Chemical Dosing',
        'equipment_failure_predictions': 'Equipment Failure Check',
        'treatment_process_logs': 'Treatment Process Control',
        'sensor_readings': 'Sensor Reading',
        'machine_status_logs': 'Machine Status Update',
        'mqtt_message_logs': 'MQTT Message',
        'system_events': 'System Event'
    }
    
    for table, activity_type in tables.items():
        logs = api_logger.get_logs(table, limit=limit//len(tables))
        for log in logs:
            log['activity_type'] = activity_type
            activities.append(log)
    
    # Sort by timestamp
    activities.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
    
    return jsonify({
        "status": "success",
        "total_activities": len(activities),
        "activities": activities[:limit],
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/water-quality-predictions', methods=['GET'])
def get_water_quality_prediction_logs():
    """Get water quality prediction logs with complete input/output + LOGGING"""
    start_time = time.time()
    
    try:
        # Get query parameters
        limit = request.args.get('limit', 100, type=int)
        offset = request.args.get('offset', 0, type=int)
        stage = request.args.get('stage', None)
        
        # Build filters
        filters = {}
        if stage:
            filters['stage'] = stage
        
        # Retrieve logs from database
        logs = api_logger.get_logs('water_quality_predictions', limit, offset, filters)
        
        response = {
            "status": "success",
            "count": len(logs),
            "logs": logs,
            "query_parameters": {
                "limit": limit,
                "offset": offset,
                "stage": stage
            },
            "timestamp": datetime.now().isoformat()
        }
        
        processing_time_ms = (time.time() - start_time) * 1000
        
        # ============================================================
        # LOG THIS API REQUEST
        # ============================================================
        api_logger.log_api_request(
            endpoint='/api/logs/water-quality-predictions',
            method='GET',
            status_code=200,
            response_time_ms=processing_time_ms,
            client_ip=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            request_headers=dict(request.headers),
            request_args=dict(request.args),
            request_json=None,
            response_json={"count": len(logs), "limit": limit, "offset": offset}  # Don't log all logs
        )
        
        # ============================================================
        # LOG PERFORMANCE METRICS
        # ============================================================
        api_logger.log_performance_metric(
            metric_type="LOG_RETRIEVAL",
            endpoint='/api/logs/water-quality-predictions',
            operation="database_query",
            response_time_ms=processing_time_ms,
            database_time_ms=processing_time_ms,
            success=True,
            error_count=0,
            details={
                "records_returned": len(logs),
                "query_limit": limit,
                "query_offset": offset,
                "filter_stage": stage
            }
        )
        
        # ============================================================
        # LOG SYSTEM EVENT (only for large queries)
        # ============================================================
        if len(logs) > 500:
            api_logger.log_system_event(
                event_type="LARGE_LOG_QUERY",
                severity="INFO",
                category="DATABASE",
                message=f"Large water quality prediction log query: {len(logs)} records",
                details={
                    "records_count": len(logs),
                    "limit": limit,
                    "offset": offset,
                    "stage_filter": stage,
                    "client_ip": request.remote_addr
                }
            )
        
        return jsonify(response), 200
    
    except Exception as e:
        processing_time_ms = (time.time() - start_time) * 1000
        error_trace = traceback.format_exc()
        
        # ============================================================
        # LOG ERROR
        # ============================================================
        api_logger.log_api_request(
            endpoint='/api/logs/water-quality-predictions',
            method='GET',
            status_code=500,
            response_time_ms=processing_time_ms,
            client_ip=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            request_headers=dict(request.headers),
            request_args=dict(request.args),
            request_json=None,
            response_json=None,
            error_message=str(e),
            traceback=error_trace
        )
        
        api_logger.log_system_event(
            event_type="LOG_RETRIEVAL_ERROR",
            severity="ERROR",
            category="DATABASE",
            message=f"Failed to retrieve water quality logs: {str(e)}",
            details={
                "error": str(e),
                "traceback": error_trace,
                "query_params": dict(request.args)
            }
        )
        
        return jsonify({
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }), 500



@app.route('/api/logs/equipment-failure-predictions', methods=['GET'])
def get_equipment_failure_prediction_logs():
    """Get equipment failure prediction logs"""
    limit = request.args.get('limit', 100, type=int)
    machine_id = request.args.get('machine_id', None)
    
    filters = {}
    if machine_id:
        filters['machine_id'] = machine_id
    
    logs = api_logger.get_logs('equipment_failure_predictions', limit, 0, filters)
    
    return jsonify({
        "status": "success",
        "count": len(logs),
        "logs": logs,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/treatment-processes', methods=['GET'])
def get_treatment_process_logs():
    """Get treatment process control logs"""
    limit = request.args.get('limit', 100, type=int)
    stage = request.args.get('stage', None)
    
    filters = {}
    if stage:
        filters['stage'] = stage
    
    logs = api_logger.get_logs('treatment_process_logs', limit, 0, filters)
    
    return jsonify({
        "status": "success",
        "count": len(logs),
        "logs": logs,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/sensor-readings', methods=['GET'])
def get_sensor_reading_logs():
    """Get raw sensor readings"""
    limit = request.args.get('limit', 100, type=int)
    stage = request.args.get('stage', None)
    
    filters = {}
    if stage:
        filters['stage'] = stage
    
    logs = api_logger.get_logs('sensor_readings', limit, 0, filters)
    
    return jsonify({
        "status": "success",
        "count": len(logs),
        "logs": logs,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/machine-status', methods=['GET'])
def get_machine_status_logs():
    """Get machine status logs"""
    limit = request.args.get('limit', 100, type=int)
    machine_id = request.args.get('machine_id', None)
    
    filters = {}
    if machine_id:
        filters['machine_id'] = machine_id
    
    logs = api_logger.get_logs('machine_status_logs', limit, 0, filters)
    
    return jsonify({
        "status": "success",
        "count": len(logs),
        "logs": logs,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/mqtt-messages', methods=['GET'])
def get_mqtt_message_logs():
    """Get MQTT message logs"""
    limit = request.args.get('limit', 100, type=int)
    topic = request.args.get('topic', None)
    
    filters = {}
    if topic:
        filters['topic'] = topic
    
    logs = api_logger.get_logs('mqtt_message_logs', limit, 0, filters)
    
    return jsonify({
        "status": "success",
        "count": len(logs),
        "logs": logs,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/statistics', methods=['GET'])
def get_comprehensive_statistics():
    """Get comprehensive logging statistics"""
    stats = api_logger.get_statistics()
    
    return jsonify({
        "status": "success",
        "statistics": stats,
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/api/logs/export/<table>', methods=['GET'])
def export_table_to_csv(table):
    """Export any log table to CSV"""
    valid_tables = [
        'api_request_logs', 'water_quality_predictions', 'chemical_dosing_predictions',
        'equipment_failure_predictions', 'treatment_process_logs', 'mqtt_message_logs',
        'machine_status_logs', 'system_events', 'sensor_readings', 'performance_metrics'
    ]
    
    if table not in valid_tables:
        return jsonify({
            "status": "error",
            "message": f"Invalid table. Valid tables: {', '.join(valid_tables)}",
            "timestamp": datetime.now().isoformat()
        }), 400
    
    try:
        conn = sqlite3.connect(api_logger.db_path)
        cursor = conn.cursor()
        
        cursor.execute(f"SELECT * FROM {table} ORDER BY timestamp DESC LIMIT 10000")
        rows = cursor.fetchall()
        
        cursor.execute(f"PRAGMA table_info({table})")
        columns = [col[1] for col in cursor.fetchall()]
        
        conn.close()
        
        import io
        import csv
        
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(columns)
        writer.writerows(rows)
        
        csv_data = output.getvalue()
        output.close()
        
        return csv_data, 200, {
            'Content-Type': 'text/csv',
            'Content-Disposition': f'attachment; filename=hydronail_{table}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        }
        
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e),
            "timestamp": datetime.now().isoformat()
        }), 400


# ============================================================
# MAIN SERVER START
# ============================================================

if __name__ == '__main__':
    
    print("\n" + "="*60)
    print("ðŸš€ Starting HydroNail ML API Server with MQTT Integration")
    print("="*60)

    if mqtt_reader.connect():
        print("âœ… MQTT initialized - receiving real-time sensor data")
        time.sleep(2)
    else:
        print("âš ï¸ MQTT not available - using API with manual sensor input")

    print("ðŸ“ API Documentation: http://localhost:5000")
    print("ðŸ”— Health Check: http://localhost:5000/api/health")
    print("ðŸ“Š MQTT Status: http://localhost:5000/api/mqtt/status")
    print("ðŸŒŠ All Stages Report: http://localhost:5000/api/all-stages/report")
    print("="*60 + "\n")

    try:
        app.run(debug=True, host='0.0.0.0', port=5000)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Shutting down...")
        mqtt_reader.disconnect()
